{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import eli5\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Import models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DosageString</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Occurances</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unparsed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"1 EVERY DAY FOR BLOOD PRESSURE AND THE HEART,...</td>\n",
       "      <td>1OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"1 EVERY NIGHT \"\" FOR CHOLESTEROL\"\"\"</td>\n",
       "      <td>1OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"TAKE ONE DAILY ,\"</td>\n",
       "      <td>1OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"TAKE ONE DAILY, TO CONTROL BLOOD PRESSURE\"</td>\n",
       "      <td>1OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DosageString Abbreviation Occurances  \\\n",
       "0                                                NaN          NaN        105   \n",
       "1  \"1 EVERY DAY FOR BLOOD PRESSURE AND THE HEART,...          1OD        n/a   \n",
       "2               \"1 EVERY NIGHT \"\" FOR CHOLESTEROL\"\"\"          1OD        n/a   \n",
       "3                                 \"TAKE ONE DAILY ,\"          1OD        n/a   \n",
       "4        \"TAKE ONE DAILY, TO CONTROL BLOOD PRESSURE\"          1OD        n/a   \n",
       "\n",
       "   Quantity  Frequency    Status  \n",
       "0       NaN        NaN  Unparsed  \n",
       "1       1.0        1.0    Active  \n",
       "2       1.0        1.0    Active  \n",
       "3       1.0        1.0    Active  \n",
       "4       1.0        1.0    Active  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8661, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the prescription text dataset\n",
    "xlsx_file = \"Dosage Parser extract - All strings - 14-08-18.xlsx\"\n",
    "data = pd.read_excel(xlsx_file, sheetname=\"WORKINGCOPY_2018_8_14_14_21_22\")\n",
    "\n",
    "# Display the first few records\n",
    "display(data.head(n=5))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Filtering and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DosageString</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Occurances</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"1 EVERY DAY FOR BLOOD PRESSURE AND THE HEART,...</td>\n",
       "      <td>1OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"1 EVERY NIGHT \"\" FOR CHOLESTEROL\"\"\"</td>\n",
       "      <td>1OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"TAKE ONE DAILY ,\"</td>\n",
       "      <td>1OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"TAKE ONE DAILY, TO CONTROL BLOOD PRESSURE\"</td>\n",
       "      <td>1OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"TAKE ONE DAILY,\"</td>\n",
       "      <td>1OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DosageString Abbreviation Occurances  \\\n",
       "1  \"1 EVERY DAY FOR BLOOD PRESSURE AND THE HEART,...          1OD        n/a   \n",
       "2               \"1 EVERY NIGHT \"\" FOR CHOLESTEROL\"\"\"          1OD        n/a   \n",
       "3                                 \"TAKE ONE DAILY ,\"          1OD        n/a   \n",
       "4        \"TAKE ONE DAILY, TO CONTROL BLOOD PRESSURE\"          1OD        n/a   \n",
       "5                                  \"TAKE ONE DAILY,\"          1OD        n/a   \n",
       "\n",
       "   Quantity  Frequency  Status  \n",
       "1       1.0        1.0  Active  \n",
       "2       1.0        1.0  Active  \n",
       "3       1.0        1.0  Active  \n",
       "4       1.0        1.0  Active  \n",
       "5       1.0        1.0  Active  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3680, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unparsed records\n",
    "filtered_df = data[data.Status != 'Unparsed']\n",
    "\n",
    "# Display the first few records\n",
    "display(filtered_df.head(n=5))\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tpham103/anaconda/envs/dog-project/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/tpham103/anaconda/envs/dog-project/lib/python3.5/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DosageString</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Occurances</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Status</th>\n",
       "      <th>quant_id</th>\n",
       "      <th>freq_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8606</th>\n",
       "      <td>USE ONE TWICE A DAY</td>\n",
       "      <td>1BD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8607</th>\n",
       "      <td>USE ONE TWICE DAILY</td>\n",
       "      <td>1BD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8633</th>\n",
       "      <td>USE TWO AT NIGHT</td>\n",
       "      <td>2OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8634</th>\n",
       "      <td>USE TWO DAILY</td>\n",
       "      <td>2OD</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>USE TWO FOUR TIMES A DAY</td>\n",
       "      <td>2QDS</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DosageString Abbreviation Occurances  Quantity  Frequency  \\\n",
       "8606       USE ONE TWICE A DAY          1BD        n/a       1.0        2.0   \n",
       "8607       USE ONE TWICE DAILY          1BD        n/a       1.0        2.0   \n",
       "8633          USE TWO AT NIGHT          2OD        n/a       2.0        1.0   \n",
       "8634             USE TWO DAILY          2OD        n/a       2.0        1.0   \n",
       "8635  USE TWO FOUR TIMES A DAY         2QDS        n/a       2.0        4.0   \n",
       "\n",
       "      Status  quant_id  freq_id  \n",
       "8606  Active         0        2  \n",
       "8607  Active         0        2  \n",
       "8633  Active         1        0  \n",
       "8634  Active         1        0  \n",
       "8635  Active         1        4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3680, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#id is easier to deal with than floats as categorical\n",
    "\n",
    "#Add id for Quantity classes\n",
    "filtered_df['quant_id'] = filtered_df['Quantity'].factorize()[0]\n",
    "quant_id_df = filtered_df[['Quantity', 'quant_id']].drop_duplicates().sort_values('quant_id')\n",
    "quant_to_id = dict(quant_id_df.values)\n",
    "id_to_quant = dict(quant_id_df[['quant_id', 'Quantity']].values)\n",
    "\n",
    "#Add id for Frequency classes\n",
    "filtered_df['freq_id'] = filtered_df['Frequency'].factorize()[0]\n",
    "freq_id_df = filtered_df[['Frequency', 'freq_id']].drop_duplicates().sort_values('freq_id')\n",
    "freq_to_id = dict(freq_id_df.values)\n",
    "id_to_freq = dict(freq_id_df[['freq_id', 'Frequency']].values)\n",
    "\n",
    "# Display the first few records\n",
    "display(filtered_df.tail(n=5))\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Grams Analysis\n",
    "source: https://www.kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DosageString by grams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3680, 1184)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using TfidfVectorizer to generate grams. This vectorizer scale down the impact of tokens that occur very frequently\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', token_pattern=r'\\w{1,}', encoding='latin-1', ngram_range=(1, 3))\n",
    "features = tfidf.fit_transform(filtered_df.DosageString).toarray()\n",
    "labels = filtered_df.quant_id #Change this between quant_id and freq_id to swap between target variable\n",
    "\n",
    "print(\"DosageString by grams\")\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label '1.0':\n",
      "  . Most correlated unigrams:\n",
      ". 1\n",
      ". 2\n",
      "  . Most correlated bigrams:\n",
      ". take two\n",
      ". take one\n",
      "  . Most correlated trigrams:\n",
      ". 1 every day\n",
      ". take one daily\n",
      "Label '2.0':\n",
      "  . Most correlated unigrams:\n",
      ". two\n",
      ". 2\n",
      "  . Most correlated bigrams:\n",
      ". 2 puffs\n",
      ". take two\n",
      "  . Most correlated trigrams:\n",
      ". two four times\n",
      ". two to be\n",
      "Label '3.0':\n",
      "  . Most correlated unigrams:\n",
      ". three\n",
      ". 3\n",
      "  . Most correlated bigrams:\n",
      ". take 3\n",
      ". take three\n",
      "  . Most correlated trigrams:\n",
      ". three three times\n",
      ". three four times\n",
      "Label '4.0':\n",
      "  . Most correlated unigrams:\n",
      ". four\n",
      ". 4\n",
      "  . Most correlated bigrams:\n",
      ". take 4\n",
      ". take four\n",
      "  . Most correlated trigrams:\n",
      ". four four times\n",
      ". four three times\n",
      "Label '5.0':\n",
      "  . Most correlated unigrams:\n",
      ". five\n",
      ". 5\n",
      "  . Most correlated bigrams:\n",
      ". capsules once\n",
      ". drops bd\n",
      "  . Most correlated trigrams:\n",
      ". once every morning\n",
      ". drops twice a\n",
      "Label '6.0':\n",
      "  . Most correlated unigrams:\n",
      ". six\n",
      ". 6\n",
      "  . Most correlated bigrams:\n",
      ". 6 tablets\n",
      ". take six\n",
      "  . Most correlated trigrams:\n",
      ". take six tablets\n",
      ". six to be\n",
      "Label '7.0':\n",
      "  . Most correlated unigrams:\n",
      ". od\n",
      ". 7\n",
      "  . Most correlated bigrams:\n",
      ". every morning\n",
      ". once every\n",
      "  . Most correlated trigrams:\n",
      ". times a day\n",
      ". once every morning\n",
      "Label '8.0':\n",
      "  . Most correlated unigrams:\n",
      ". od\n",
      ". 8\n",
      "  . Most correlated bigrams:\n",
      ". tabs daily\n",
      ". tablets od\n",
      "  . Most correlated trigrams:\n",
      ". taken in the\n",
      ". once every morning\n"
     ]
    }
   ],
   "source": [
    "# using chi2 to find the terms that are the most correlated with each quantity\n",
    "N = 2\n",
    "for Quantity, quant_id in sorted(quant_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == quant_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  trigrams = [v for v in feature_names if len(v.split(' ')) == 3]\n",
    "  print(\"Label '{}':\".format(Quantity))\n",
    "  print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "  print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n",
    "  print(\"  . Most correlated trigrams:\\n. {}\".format('\\n. '.join(trigrams[-N:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining probability thresholds through Kfold CV based on Precision at K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2465, 1184)\n",
      "(2465,)\n",
      "(1215, 1184)\n",
      "(1215,)\n"
     ]
    }
   ],
   "source": [
    "#splitting the data\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, filtered_df.index, test_size=0.33, random_state=17)\n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 1.0,\n",
       " 1.0: 2.0,\n",
       " 2.0: 3.0,\n",
       " 3.0: 4.0,\n",
       " 4.0: 5.0,\n",
       " 5.0: 6.0,\n",
       " 6.0: 7.0,\n",
       " 7.0: 8.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.120334</td>\n",
       "      <td>94.156507</td>\n",
       "      <td>90.784779</td>\n",
       "      <td>93.474185</td>\n",
       "      <td>93.403432</td>\n",
       "      <td>98.911853</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.154702</td>\n",
       "      <td>97.790214</td>\n",
       "      <td>91.620691</td>\n",
       "      <td>91.813885</td>\n",
       "      <td>82.529378</td>\n",
       "      <td>79.015669</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.129422</td>\n",
       "      <td>57.646491</td>\n",
       "      <td>83.022612</td>\n",
       "      <td>88.855405</td>\n",
       "      <td>67.060555</td>\n",
       "      <td>88.749593</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.804443</td>\n",
       "      <td>61.748109</td>\n",
       "      <td>93.242150</td>\n",
       "      <td>86.749206</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.396322</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.075481</td>\n",
       "      <td>83.264490</td>\n",
       "      <td>51.826090</td>\n",
       "      <td>86.959301</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>92.024152</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.195664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.059724</td>\n",
       "      <td>94.530231</td>\n",
       "      <td>94.535744</td>\n",
       "      <td>86.457105</td>\n",
       "      <td>67.785983</td>\n",
       "      <td>92.569106</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76.960217</td>\n",
       "      <td>89.163086</td>\n",
       "      <td>82.453774</td>\n",
       "      <td>51.620998</td>\n",
       "      <td>93.844120</td>\n",
       "      <td>85.042161</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.856511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76.710943</td>\n",
       "      <td>51.556454</td>\n",
       "      <td>97.191740</td>\n",
       "      <td>96.729290</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>95.974471</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.213295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70.982831</td>\n",
       "      <td>79.283149</td>\n",
       "      <td>93.206939</td>\n",
       "      <td>94.025929</td>\n",
       "      <td>90.597277</td>\n",
       "      <td>91.469331</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.800903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91.923999</td>\n",
       "      <td>91.231227</td>\n",
       "      <td>97.045526</td>\n",
       "      <td>95.821831</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.882066</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.824453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0.0        1.0        2.0        3.0         4.0        5.0    6.0  \\\n",
       "0  82.120334  94.156507  90.784779  93.474185   93.403432  98.911853  100.0   \n",
       "1  71.154702  97.790214  91.620691  91.813885   82.529378  79.015669  100.0   \n",
       "2  80.129422  57.646491  83.022612  88.855405   67.060555  88.749593  100.0   \n",
       "3  93.804443  61.748109  93.242150  86.749206  100.000000  97.396322  100.0   \n",
       "4  94.075481  83.264490  51.826090  86.959301  100.000000  92.024152  100.0   \n",
       "5  77.059724  94.530231  94.535744  86.457105   67.785983  92.569106  100.0   \n",
       "6  76.960217  89.163086  82.453774  51.620998   93.844120  85.042161  100.0   \n",
       "7  76.710943  51.556454  97.191740  96.729290  100.000000  95.974471  100.0   \n",
       "8  70.982831  79.283149  93.206939  94.025929   90.597277  91.469331  100.0   \n",
       "9  91.923999  91.231227  97.045526  95.821831  100.000000  97.882066  100.0   \n",
       "\n",
       "          7.0  \n",
       "0  100.000000  \n",
       "1  100.000000  \n",
       "2  100.000000  \n",
       "3  100.000000  \n",
       "4   94.195664  \n",
       "5  100.000000  \n",
       "6   97.856511  \n",
       "7   99.213295  \n",
       "8   96.800903  \n",
       "9   97.824453  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average probability threshold for each class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 81.492209548123924,\n",
       " 1.0: 80.036995872062363,\n",
       " 2.0: 87.493004478227164,\n",
       " 3.0: 87.250713518002016,\n",
       " 4.0: 89.522074503527648,\n",
       " 5.0: 91.903472392294191,\n",
       " 6.0: 100.0,\n",
       " 7.0: 98.58908267355541}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "col_names = id_to_quant\n",
    "id_to_thresholds = pd.DataFrame(columns=col_names)\n",
    "\n",
    "target_precision = .99\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=100)\n",
    "kf.get_n_splits(X_train)\n",
    "\n",
    "#run kfold CV to get the average probability threshold that reach target precision\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_cv, X_val = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    #train and predict\n",
    "    model = LinearSVC(random_state=0)\n",
    "    model.fit(X_train_cv, y_train_cv)\n",
    "    calibrated_svc = CalibratedClassifierCV(base_estimator=model, cv=\"prefit\") #calibrate the svc model to get probability output\n",
    "    calibrated_svc.fit(X_train_cv, y_train_cv)\n",
    "    y_pred = calibrated_svc.predict(X_val)\n",
    "    prob_pred = []\n",
    "    posterior_prob = pd.DataFrame(calibrated_svc.predict_proba(X_val)*100, columns=calibrated_svc.classes_)\n",
    "    for index, row in posterior_prob.iterrows():\n",
    "        data = row[y_pred[index]]\n",
    "        prob_pred.append(data)\n",
    "    \n",
    "    #build precision at K (PatK) data\n",
    "    PatK_df = pd.DataFrame(\n",
    "    {'predicted': y_pred,\n",
    "     'actual': y_val,\n",
    "     'confidence': prob_pred\n",
    "    })\n",
    "    PatK_df = PatK_df.sort_values('confidence', ascending=False)\n",
    "    \n",
    "    #calculate threshold based on precision at K for each class\n",
    "    thresholds = []\n",
    "    for quant_class in id_to_quant:\n",
    "        k_counter = 1\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        k_value = []\n",
    "        precision_at_k = []\n",
    "        confidence_at_k = []\n",
    "        predicted_at_k = []\n",
    "        actual_at_k = []\n",
    "        for index, row in PatK_df.iterrows():\n",
    "            if row['predicted'] == quant_class:\n",
    "                if row['predicted'] == row['actual']:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1    \n",
    "                precision = TP/(TP+FP)\n",
    "                precision_at_k.append(precision)\n",
    "                confidence_at_k.append(row['confidence'])\n",
    "                predicted_at_k.append(row['predicted'])\n",
    "                actual_at_k.append(row['actual'])\n",
    "                k_value.append(k_counter)\n",
    "                k_counter += 1\n",
    "        class_PatK_df = pd.DataFrame(\n",
    "        {'k_index': k_value,\n",
    "         'precision': precision_at_k,\n",
    "         'confidence': confidence_at_k,\n",
    "         'predicted': predicted_at_k,\n",
    "         'actual': actual_at_k\n",
    "        })\n",
    "        #display(class_PatK_df)\n",
    "        #class_PatK_df.plot(x='k_index', y='precision')\n",
    "        \n",
    "        #get confidence threshold that maintain target precision for this class\n",
    "        threshold = 100\n",
    "        for index, row in class_PatK_df.iterrows():\n",
    "            if row['precision'] < target_precision:\n",
    "                break\n",
    "            threshold = row['confidence']\n",
    "        thresholds.append(threshold)\n",
    "    \n",
    "    #save thresholds for this fold    \n",
    "    id_to_thresholds.loc[len(id_to_thresholds)] = thresholds       \n",
    "#END of Kfold CV loop\n",
    "\n",
    "display(id_to_quant)\n",
    "display(id_to_thresholds)\n",
    "print(\"Average probability threshold for each class:\")\n",
    "avg_thresholds = np.mean(id_to_thresholds)\n",
    "qty_avg_thresholds = avg_thresholds.to_dict()\n",
    "display(qty_avg_thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Selection\n",
    "Benchmarking with the following four models:\n",
    "* Logistic Regression\n",
    "* (Multinomial) Naive Bayes\n",
    "* Linear Support Vector Machine\n",
    "* Random Forest\n",
    "\n",
    "source: https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tpham103/anaconda/envs/dog-project/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/tpham103/anaconda/envs/dog-project/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/tpham103/anaconda/envs/dog-project/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/tpham103/anaconda/envs/dog-project/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYHFW5+PFv9TJbz0wyM5nse0JOQoCwJCEIgUAIIIIg\nV5FVgcsPEb0KKC6IV9SruACKC96LF0VBRJSdK2FJCAhhCSEEyPImIfuezExmn+nprvr9cWomPWtm\n6+mZ9Pt5njyZrq3f6q4+7zmnqk45nuehlFIq/QRSHYBSSqnU0ASglFJpShOAUkqlKU0ASimVpjQB\nKKVUmgqlOoDO2revUi9XUkqpLiouznPam6ctAKWUSlOaAJRSKk1pAlBKqTSlCUAppdKUJgCllEpT\nmgCUUipNaQJQSqk0pQlAKaXSVFJvBDPGnAj8VETmtZh+PvCfQAz4g4j8PplxqP7D8zzWrFnFkiWL\n2LZtC57nMWrUGE477QyOOuoYAgGtkyjVV5xkPQ/AGPMN4EqgWkTmJEwPA2uAWUA18Dpwnojs6Wh7\neifwwFdbW8O9997DqlUftDl/5MhRjB8/kXg8Tm5uLjNnnsiUKVNxnHZvZFRKHUJHdwInswXwEXAR\n8GCL6dOADSJSBmCMeQ04Ffh7RxsrKMghFAomI07VB+LxON/73k9t4Z8RIDQ1l+CYbHAgvqOW2Joq\ndu7cwc6dO5rWWbToBSZMmMAtt9zCmDFjUhi9UoenpCUAEXnMGDO+jVn5QHnC60pg0KG2V1ZW00uR\nqVRYseIdVq5cCZkBMs8ZSiDv4KEXGBwmNCFC/fN78arjBI+I4GQGiG2oZtOmTXzjG9/kO9/5PsOG\nDU/hHig1MBUX57U7LxUdrhVAYkR5wIEUxKH60MsvvwRA+Ki8ZoV/IycnSOiYfADcsgbCxw4i68Lh\nBEZkUlVVyV//+uc+jVepdJCK0UDXAEcYYwqBKmz3z50piEMl0aOP/oVly95qel1aWgJAYGw28b31\nxNdV4e6L4sU9ArkhgpMiBMZkAuCVRPE8DycUIOPkQuoe38X777/HzTd/iWCwa92As2adyMUXX957\nO6bUYaTPEoAx5jIgV0TuM8bcDDyPbYH8QUR2dLy26ks//vHtlJWV9mgb1dXVRKP1Ta8bLzZoWF6O\nu7W22bJuXRR3fxQ+8At3z//ngJMVJDg6m/jWWsrLD3T5hPCSJYubJaLuKCgo5NZbb+/RNpTqj5Ka\nAERkMzDH//vhhOnPAM8k871V95WVlVJSup9Adg8OjwCQldDDWOuChy38Q449CTw+ByfsEN9TT2x1\nFd6BBrtsTgAnkFDQZ/uJIeRAuGu9llEaiNZ2v4fRrY11e12l+rsB80AY1bcC2SEKzhnba9urWVVK\nrRyAIGQuKCZQlNE0LzQxRHBsDtHF+3D3RnEizQ9LryQKQOTYIWSOye21mDqjbOHWPn0/pfqS3nWj\n+oRbHwewff0JhX8jJ+QQPn4wAF55A17cdhnF99Xj7o/ihBwyRuT0XcBKpQFtAahWqqurcetjvVr7\ndetsV0pwbHa7ywSGZOBEgnjVcdyqBqh2iS615yI84MBL23stns5ya2NUu9V9/r5K9QVNAKpvBQ9x\nEtfv+48uKoGaeNM0p4t9/0qpQ9MEoFqJRCJEAw29eg6g8p29RLdW4e6oI1ic2eYybkUDXqV/0rUm\njpMVJGtCPtlmcPOTwn2obOFWItmRlLy3UsmmCUD1iazxeUS3VhFbV03wiAiBlid6PY/YygoAQsVZ\n5EwtIFSUlbKCX6l0oO1q1SdCRVmEirMg6hJ9fh+xjdVNJ3rd/VGir5QQ31ILQYfIjCGEi7O18Fcq\nybQFoPqE4zjknTiMyqW7iZXW07C0jIY3yuw5gZg/0GvILhPKb32VkFKq92kCUH0mkBEkf+5I6rdW\nUrexgnh5FGIeTkaAzHF5ZE3MJxgJpzpMlcbq6+t4443XeeWVxezatRPHgbFjxzNv3nxmzZpDKNR+\nkem6LqtXf8irr77M3r17CAaDTJw4mXnz5jNq1Og+3IvO0wSg+pQTdMiakE/WhHy8uIvn2nsAOjvE\ng9vgEt1WRaysHjyPQG6YrHF5PbtrWSlg7949/OIXP2XPnt3Npq9fL6xfL7z44kJuvPEW8vNbD15c\nXn6AX/3qLjZt+qjZ9E2bPmLRoueZN28+l19+VZfHsko2/dWolHGCAZxO/h48z6NuQzk1a8oOdhn5\nateUkTk+j8iMIXreQHVLbW0Nd9/9E/bu3UNWRgEjC49jUGQs4FJauYldpSvYvHkj99xzJ9/+9vea\ntQRqa2u588472LFjG+FgNkMHTyc/ZzSuF6O08iP2VwhLlizC8zw+//lrU7eTbdCTwGpAqF17gJoP\nSiHmERiaQXjWYMInFhDwbyyr31RJ1dt7SNYT7tTh7V//WsLevXvIzijkyLEXUJQ/mVAwg1Awi6GD\np3Hk2AsJhyJs2vQR7723vNm6S5a8xI4d28gKD2L6uE8zsuh4crOHkp8zkvHD5mJGn4fjBHnllcVs\n29a/hhbRBKD6vXhllNo1ZeBA+ORCMs8aSsjkEjoiQuapRWSeMxQyHKI7a4hu17t2VdctWbIIgFFD\nZhIMtL4IIRzKYUTBDODgsy3Atkwb1x1TPIdwqPWd7nnZwynON/66L/Z67D2hXUCq36vbaO8PCE7M\nITSh9XhAgaIMwjMG0bDsAHUbK/p8wDjVt3o6XHlbQ5XblqPD4Ej7Nz8W5I5n676lrFmzimuvvaLZ\nusFABoMi7T+2tCj/CPaWr2bJkkW8+urLTdMzMjKJRHp2o2FPhivXBKDa5Nb27lhA3Yoh6g8F4d8v\nEJzc/g8lODGHhncOECupo/S5Lb32IHm3NgbtD1+kUqCsrJSSkhIyw90bHDAWj+G6iV2Fne02PHhM\nHVzf/h9wQjhO+x0qgcDBq9sS37shGqMqXtvWKp1S39CzR+VqAlCtFBQUpjoEAMrq/Fqe4+B6Lk52\n+2eMnXDAPisg6jI4axCBQC/1bmb3n89DHZQZzuH4af/Wa9tbsfYJ6qKVlFdvY3DuuDaXOVC9GYD8\nyHCmTzoLANeNs2zV32iI11AbPUB2xuA2162osc+8Gpw3imkT5vda3O+ueaxH62sCUK30l6df3XLL\nVwDIy8tn8+aNeKUNkNv2IetWxSDqEgqF+elPf9nh9dpKtTSsaApbdi1nR8k75OWMJBhofj9KQ6yW\nXaUr/WWPaJoeCAQZUjCBvaXr2VnyLhOHn96q9RmLR9l74EMAhhZOTvKedI2eBFb93pw5JwMQW1PZ\n7lU+sTVVgH0GsBb+qquGFh5BZjhCTX0Ja7Y9TWnlRlw3RtxtYH/5OtZse5JorIpIViGF+c3PE4wY\nMg3HCVBauYFNu5dQF7XnrDzPo6JmJ7L9WeobKsnOHERBfvvnCVJBfymq3zv55Lk8/fRj1OyroWFp\nGeETBuFk2e4gL+YSW1NFXKpwHIczzzwnxdGqgSgUzGDaxAWs2fgStfUlfLTrpVbL5GQVMHXCGQQC\nwRbTBzNl7Gms2/oKJZXrKalcT2Y4D9eN0xC3ffSZGbl23Q7OE6SCJgDV70UiuXzpSzdxzz0/J7qp\nhviWGgLDMiHo4O6th6htFVx++VVMmDAxxdGqgSo7M59jppzHvrKP2FOyntr6chwgJ7uQ4UVTGDJ4\nYqvCv1HhoDEcPfkT7Nq/mv0HNlHfUAlAOJTF0MIpjBgylXAoqw/3pnM0AaiUamho4L33lrNnz26C\nwSATJkzCmGmt+lGnTZvOt799O08++Xfef/893F0HL+ObOHEy5513Iccee3xfh68OM6FgBiOGTGPE\nkGlN3Y2dvaIskl3A5DEnM2HkbKINNThOgIyMSL+r9SfSBKBSwvM8nn/+//jnP5+hqqqy2bwRI0bx\n2c9e1mqdcePG89Wv3sL+/fvYsmUznucybNgIxozpvQfXKNWou5cSB4NhsoOtxwvqjzQBqD7neR4P\nP/xnFi16HgCnIExwRCZe3CO+tZZdu3Zwzz13EonkkpnZ+ulhQ4YUM2RIcV+HrdRhRxOA6nMrV66w\nhX/AIeOUQgJjsppqW94Jg4m9X0Hsw0qqqioJh3V4aNW/NMTqKC3fSjRWSzAQYnDeKHKy2r7+v7/T\nBKD6XGPNPzQjj+DY5rfZOgGH0Ix83NIo7s566uvrUhGiUq3E4w1s3rmMfQc24nlu0/Qtu5aTHxnG\nhFEnDrhE0H/PTqjDUm1tLatWfQAOhCa3PWaP4ziEpth59fXRvgxPqTbF3QZWb3qRvWUb8DyXQZEx\njCg8jiH5Uwg4YSqq9/DhRwupqStLdahdoi0AlRSPPvoXli17q9X0eNwf3ycrgJPZfv3DyQ/5y8ea\n7gjujlmzTuTiiy/v9vpKAWzf8z5VNfvJCOUyZdTHyc4saJo3pvhjbNy9mPLqrazf+hrHHHFer41F\nlWzaAlB9KtD4wJY6F6/ebXc5ryIGdP9KDKV6S9yNsad0PQCTRsxvVviDvXR00ogzCQWzqakro7Jm\nbyrC7BZtAaikuPjiy9uted911x2sWvUBsQ3VhKfntZrveR6xdXZc/4suuphPfOKCpMaqBpbq6mrq\nG+p6PBBaZ7lujHg8Sk5mEbnZw9pcJhgIMSR/CrvLVrJ20yJCwdZXryVDfUMNTnX7FalD0RaA6nPz\n558NQGxlBfGttc3G9/Fcj9jKCtyddYTDYebOnZeiKJWyGo/OrIyOr+1vnD+QHkqnLQDV52bMOI75\n889i0aIXiL5aknAfAMS31kCti+M4XHPNF9p8ALdKb5FIBC8e6NXhoDtSVrmDtZsWURst73C5On/+\nsKIjGD9yVl+ExrtrHiMS6f4DKzQBqD7nOA6XXfZ5CguLeO65Z6kqqyRW1tA0f8SIkVx88eXMmHFc\nCqNUysqPDCMUzKC2voTK2t3kZQ9vtUzcbWB/hQBQOKjt5wn0R5oAVEo4jsPHP34+Z555Du+9t5zd\nu3cTDAaYOHFym2MBKZUK0YZa9h/YRGY4l1i8lI27FnHEqHPIySxqWiYWr+OjXYuJxeuIZBWSlzNw\n7lLXBKBSKhwOM2vWnFSHoVQzrhtn885lTdf9N4rGqlm15THyc0aRkzmEaKyaA1WbcL04oWAmk8ee\nMqAqL5oAlFIqgeu5yJaXOVC5E/ug+HHk5YygIVbL3vI1uG6UipodTY95BBiUO4IJo04kOzM/dYF3\ngyYApZRKsLdkHQcqdxIKZjFl1LlEsoY0zRs9ZDbb97/N7rKVOE6AMcNmUJg/luysgXmxgl4GqpRS\nPs/z2F1iT+aOLf5Ys8If7Lmr0UNmk5c9Es9zCQRCA7bwhyS2AIwxAeBeYAZQD1wrIhsS5l8J3AKU\nAw+IyP3JikUpdXipb6hJyo1gnuf6o3xmUpDX9tPlHMeheNBUKmt3smXXcnbtW93rcXRWfUMNufTP\ny0AvBLJE5CRjzBzgLuACAGPMEOCHwPHAAeAlY8wiEdmcxHiUUoeBgoLCpG07FosRLa8lI5TT4ZO8\nMsP2DvZAIEBufvcL4J7KJbtHn0cyE8ApwEIAEXnTGDMzYd5EYKWIlAIYY5YBc4DNSYxHKXUYuPXW\n25O27bKyMr72tS9R31BJ3I0SDGS0uVxNfQkA06cfzY033pK0eJItmQkgH9u90yhujAmJSAxYD0w3\nxgwDKoH5wLqONlZQkEMo1PYDmZVSqjcUF+cxffp0Vq1axb5yYXjB0a2W8TyXvQdst8+ZZ55OcXHr\n8awGimQmgAog8ZMJ+IU/IlJmjLkJeAwoAd4F9ne0sbKymmTFqZRSTU47bQGrVq1i+/63CAWzKMqb\n3HRtfyxex+Y9r1EbLcVxAhhzDPv2VR5ii6nVUYJKZgJ4HTgfeNQ/B/BB4wxjTAjb/z8XyABeBG5N\nYixKKdUpJ5wwizPPPIeXXlrIpt0vs7PkHfKyRxBzo5RXb8Pz4jg45OXlEQ633UU0UCQzATwBLDDG\nLAUc4GpjzGVArojcZ4wBW/OvA+4SkQ5bAEop1Rccx+HSS69k+PARPPfcM5SU7Ke+4WAtf/r0o9m+\nfRuh0MC/jcrxBsjYpfv2VQ6MQJVShw3XdVmzZhX79+8jFAoxefIUhg0b3vSUup///FcpjvDQiovz\n2h2bYuCnMKWUSpJAIMD06a1PBB8u9E5gpZRKU5oAlFIqTWkCUEqpNKUJQCml0pQmAKWUSlOaAJRS\nKk1pAlBKqTSlCUAppdKUJgCllEpTmgCUUipN6VAQSinVSxoaoixb9hYrVrxDTU0Nubl5zJw5m+OO\nm9kvB4/rfxEppdQAtGrVB9x332+prKxoNn3ZsjcpLCzihhu+ysSJk1MUXdu0C0gppXpIZA333PNz\nKisryM4sYtzQU5gy6lzGFJ9EVngQpaUl/PznP2br1i2pDrUZTQBKKdUDnufx0EN/JBaLUTxoGtPH\nXsTQwUcyKDKa4QVHM338ZyjInUh9fR2PPPJgqsNtRhOAUkr1wLp1a9mxYzvhYDZjh36s6fGRjQJO\ngPHDTiXghFi7djU7d+5IUaSt6QNhlFJp5dFH/8KyZW/1aBtlZaUAFBQUUlNTQ21tDcMGH8XYoR9r\nd52Pdi2mtHIDkUiErKxsAGbNOpGLL768R7Ecij4QRimlelFGRmbCK1s3DQWzOlwnFLTr9Kc6t7YA\nlFKqB15++UUefPCP5OeMxow+t81lPM9j9dbHqakv4YYbbmTmzNl9Fl9HLQA9B6CUUj0wa9YcQqEw\nFTXbqa7b1+YyFTXbqakvITc3lxkzju3jCNunXUBKpSHP89i48SPWrVtDLBajqGgIxx8/i6ysjrsx\nVGu5uXmceuo8Fi9+kXU7FjJ+6CkMzh2H4wRwvTillRvZuvd1AObPP5twOCPFER+kXUBKpZn164WH\nH/4TW7ZsbjY9OzubM844iwsv/DTBYDA1wQ1QDQ1RfvWru1i16gMAwsEcMsN51DWUE4vXATB79hyu\nu+7LBAJ92/HSUReQJgCl0sjq1R/yy1/+jFgsRjYwlQCZwDY8dvgnM2fOnM3113+lzwuqgS4Wi7Fo\n0fO8/PJL7N27p2n6yJGjmD//bE477YyUfKaaAJRSRKNRvv71/6CqqpJjCXCmEySUcM36Fs/lcS9G\nPfC5z/078+bNT12wA5jruuzcuZ2amhoikVxGjhzV6t6AvqQngZU6jMViMbZu3cKGDesoKdnf7nJv\nvbWUqqpKhuFwdovCH2CcE2CBY7t+Fi9+gYFSOexvAoEAo0ePZcqUqYwaNTqlhf+haAtAqQGgrZuX\nXNelrq6Wurp6PM9tmh4KhcjOzm52rXp1dTXRaD2u63KOE+RYp+0+/rjn8WuvgTpg8OCCVucC+uLG\nJdW7tAWg1GHGdV0qKsqpra3F81zygRE4hLEtgsrKSmpqapqWbyz8AQppv0YadBwG+/Mbl1eHL20B\nKDUA3XXXHaxa9QGFwNlOiLE4OI5DveexApdXvDge8MUvfoVZs+Zwyy1foby8nFisocMWQMzz+I3f\nArjjjrsZNmx4X+6WSgJtASh1GNmyZTOrVn1AJnCpE2acE2jqZ850HOY4QU73C/iFC59tWq+xK3qF\n57bbv78Glzr/7/74ABPVu7QFoFSS/fjHtzcNHtYbqqurqKur4wQCLAi0XUg3eB6/9WvygwYNprKy\nolmXzgz/KqBwO1cBAeTl5ZOR0fs3LRUUFHLrrbf3+nZV23QwOKVSaPv2bdTV1XbQ8941jTWhMU77\nDfiw4zDcc9iMR3n5gWbzAsBKXMRzmeoFyAK24rHT33I2UAtUVlb0WsyJsVdXV/fyVlV3aQJQqg84\nQG4v3QRU67rEgDo6bhQ3duVkOw4h//xA1PMYDURx2I3HexxsFWQCRxNguT8t4jgEevkSxio9sdyv\ndCoBGGMuA6YDPwI+LSJ/TmpUSh1GIpEI4Wg9Vwwq7JXtraqv5dWaaj703HZP5u73PHbjEQIuG1RA\nhhOgyo3zUHkZ24BLnSBhbM0/DgwCJnsOL+LiARPCGZyTm98r8SZ6qLyUjEik17eruueQVRJjzE+A\nc4GLsAnjamPMXckOTCnVtiMyMgnjsB2P5V681fx6z+M5LwbAlIwsMvyuotxAkKMzs/CAR70Y6z2X\nKQQ4gQA5ODxJnA9xCQEzs3L6cI9UqnSmBXA2cDzwrohUGGMWAO8DX0tqZEqpNmU4AU7OibCkpooX\nvTjrPZejnQARHHbiscKLUwlEnAAzs7ObrXtSdoSo57E2Ws9SXJZ6zbtkAtjCv0gHg0sLnUkAjUdI\nY4djZsI0pVQKTPNr8q/XVLEZj80tWgKFgSDn5OYTCTQvyAOOw7ycXExGFu/X17KlIdrsx+wCb9bV\nINF65kVyGR4KJ31fVOp0JgE8CvwNKDTG3AhcCTyc1KiUUod0ZGYWE8MZSLSe7Q1RYkAkEGBKRiZj\nQuF2x6BxHIfiUIjK2jguttZvCDDCcaj2PFbhUubGebqynPNyBzEyrEngcNWZBHAncCawBRgLfE9E\nnu14FTDGBIB7gRlAPXCtiGxImH85thspDvxBRH7X9fCVSm9ZgQAzsrKZkZV96IUTvFNbw/54nMHA\nJU6YwY3JwoFTPY/nvTjv47K4ppLL8gt6/Wog1T90JgEsE5Hjgee7uO0LgSwROckYMwe4C7ggYf6d\n2CuLqoDVxphHRKSsi++hlOqimOexJmovEj3fCR0s/H1Bx+Ecgmz1XA64Llsaokxo9hB0dbjoTALY\nY4yZC7wtIvWHXPqgU4CFACLypjFmZov572OvPothL5PWO33VYavKdXmovPt3A9f51/73hsYfWjEO\nI9u51SvgOMwgyCtenIXVlTjVlYAtMLJ6cD9DlevSOxfDqt7QmQQwE3gFwBjTOM0TkUNdJpAPlCe8\njhtjQiLSeBx/CCwHqoHHReRAyw0kKijIIRTSKxPUwDN0aDHBYM9uAotXVRGvqzv0gp3heXieRz50\nOFb9oIS/Hb/QD2dlkZ2b2+23zgaKioooLs7r9jZU7zlkAhCR4m5uuwJI/JYDjYW/MeYY4BPABGwX\n0EPGmM+IyN/b21hZWU17s5Tq12655bupDqGZ9euFO+74PvuxiaC9JLDPHyfs9NMXcOWVV/dqDPv2\nVfbq9lT7Okq2h0wAxpgc4HvAfH/5xcB3ReRQA3q8DpwPPOqfA/ggYV45driRWhGJG2P2AgWHikUp\n1XOTJh1BUdEQSkr2sx6PKW10A0U9j5X+BaKzZ8/p6xBVH+lMu/Q3QAS4Bvg8kAH8dyfWewKoM8Ys\nBX4B3GSMucwYc52IbAH+B3jNGPMaMBh4oBvxK6W6KBAIcMYZCwD4pxdjc4vhoSs9j8e8GDXA2LHj\nmDJlaooiVcl2yOGgjTErRWRGi2mrReTIpEbWgg4HrVTvicfj3HvvL1mxYjkAQ3EYgUMVHpvwcIH8\nvHy+9e3vMXz4iNQGq3qkpw+ECRhjBje+8P/urQsSlFIpEAwGueGGG/nkJy8iNzePvdgun4/wIBDg\nhBNm8Z3bfqCF/2GuMy2Aq4Fbgaf9SZ8E7hCRPyQ5tma0BaBUcjQ0RPnww/c5cOAAmZmZTJ16JIWF\nRakOS/WSjloAnXoimDHmKOA0bIvhZRH5sPfC6xxNAEop1XU96gIyxhwN3CYivwVeAu41CTcEKKWU\nGpg6cw7g9/hX6IjIGuCHwP1JjEkppVQf6EwCiIjIwsYXIvIi9rJQpZRSA1hnhoLYa4y5HnjIf30p\nsCd5ISmllOoLnWkBXA2cB+zCDgl9LnBtMoNSSimVfJ26CqiRMWYQMFpEViUvpLbpVUBKKdV1PboM\n1Bjz78DJwDeBFUAl8JiI3NabQR6KJgCllOq6nt4JfAPwdWzf/1PA0cA5vROaUkqpVOnUIOUiUort\n+/8/f0jnrj1/TimlVL/TmQSwyhjzLDAReMkY8yiwLLlhKaWUSrbOJIBrgJ8Bc0QkCjyIfxWQMea8\nJMamlFIqibp0FVBLxph3/QfGJ52eBFZKqa7r6UngjrT/QFGllFL9WmfuBO6I1sqVSqF9+/ayZMki\n1q1bQ0NDjKKiIk4++VRmzDieYDCY6vBUP9fTBKCUSgHP83jyyX/w7LNPNnuc49atm1mxYjkjRozi\nq1/9OkOHDkthlKq/a7cLyBjzWf//IX0XjlKqM5566jGeeeYJ8DymE+CzTojPOyHOcIIMAnbt2sHP\nfvZflJeXA7B27WrWrl2d2qBVv9PROYDvG2NCwAsdLKPnAJTqY2VlZTz77JMAfMoJcX4gxAQnwAgn\nwGwnyDVOmJE4lJaW8NxzzwA2YTz11GOpDFv1Qx11AS0F6gHHGBNPmO4AnogEgZOSGZxSqrVXX12M\n67oYHKY4retwmY7DAoL8yYvx2muvMH360dhHediWwNSpR/Z1yKqfajcBiMg1wDXGmKdE5IJ2lqlL\nWmRKqTZt2LAOgCOd9k/yjnACFHhQVlPN448/2jT9qace0wSgmhzyMtD2Cn+lVGrE47ZBnnmI5TL8\nHtqe3OujDm89vQ9AKdXHhgwZCsAWz213mWrPYx8ejuNw3nkXNk2/4IJ/S3p8auDQBKDUADN37mkA\nvIdLVTu1+ze9OC4wY8ZxzJw5G2OmYcw07f5Rzeh9AEoNMJMnT2HKlKmsW7eWh70G5hNiIg6O41Dh\nebzlxVmOi+M4nHOOHa5La/6qLT0aC6gv6VhASh1UUVHOnXfewfbtWwHIwZ4TOIC9Pd9xHK666v8x\nd+681AWp+oUePRGsv9AEoFRztbW1LF78AkuWLKKkZD8AwUCQ446fydlnn8ukSUekOELVH2gCUOow\n5rouJSX7aWhoYPDgAnJyclIdkupHOkoAeg5AqQEuEAhQXDw01WGoAUivAlJKqTSlCUAppdKUJgCl\nlEpTmgCUUipNaQJQSqk0pQlAKaXSlCYApZRKU0m7D8AYEwDuBWZgHyxzrYhs8OcNBx5JWPxY4Fsi\n8t/JikcppVRzybwR7EIgS0ROMsbMAe4CLgAQkd3APABjzEnAj4DfJzEWpZRSLSSzC+gUYCGAiLwJ\nzGy5gDHGAX4NfFFE4i3nK6WUSp5ktgDygfKE13FjTEhEYgnTzgdWiYgcamMFBTmEQu0/Ak8ppVTX\nJDMBVAA2bdLKAAATmElEQVR5Ca8DLQp/gCuAezqzsbKymt6KSyml0kZxcV6785LZBfQ6cC6Afw7g\ngzaWmQksTWIMSiml2pHMFsATwAJjzFLAAa42xlwG5IrIfcaYYqBCRHSYZ6WUSgF9HoBSSh3GOnoe\ngN4IppRSaUoTgFJKpSlNAEoplaY0ASilVJrSBKCUUmlKE4BSSqUpTQBKKZWmNAEopVSa0gSglFJp\nShOAUkqlKU0ASimVpjQBKKVUmtIEoJRSaUoTgFJKpSlNAEoplaY0ASilVJrSBKCUUmlKE4BSSqUp\nTQBKKZWmNAEopVSa0gSglFJpShOAUkqlKU0ASimVpjQBKKVUmtIEoJRSaUoTgFJKpSlNAEoplaY0\nASilVJrSBKCUUmlKE4BSSqUpTQBKKZWmNAEopVSa0gSglFJpShOAUkqlKU0ASimVpjQBKKVUmtIE\noJRSaUoTgFJKpalQsjZsjAkA9wIzgHrgWhHZkDB/FnA34AC7gStEpC5Z8SillGoumS2AC4EsETkJ\n+BZwV+MMY4wD/B64WkROARYC45IYi1JKqRaS1gIAGgt2RORNY8zMhHlTgBLgJmPMUcD/iYh0tLGC\nghxCoWDSglVKqXSTzASQD5QnvI4bY0IiEgOGAB8DvgxsAJ41xrwjIovb21hZWU0SQ1VKqcNTcXFe\nu/OS2QVUASS+c8Av/MHW/jeIyBoRacC2FGa23IBSSqnkSWYL4HXgfOBRY8wc4IOEeRuBXGPMZP/E\n8Fzg/iTG0uuqqipZvPglli9/m8rKCgCys3MYOXIkQ4cO54QTZjFx4uQUR6mUUu1zPM9LyoYTrgI6\nBnulz9XA8UCuiNxnjDkD+Ik/b6mIfLWj7e3bV5mcQLvI8zyee+4ZHn/877huvMNlJ06czLXXfpHh\nw0f0UXRKKdVccXGe0968pCWA3tZfEsDTTz/Ok0/+4+CE7BGQPxkCGVC7ByrWgRvF5jWPYDDIkCHF\n5OTkMHXqdObNm09x8dBUha+USjOaAHrJ3r17+Na3bjo4YejJMHha84Vi1bDtn9BQDuE8aKhsNttx\nHC688NOcd96FOE6734tSSvWKjhKA3gncBUuWLDr4Imd068IfIBSBYSfbv90YTR/x0LmQNwnP83ji\nib+zcOGzSY9XKaU6cti0AG6++UtUVJR3tEiHXNcDuvBZjDgd8ia1Pc/zYNMjtjWQMwZqtkHxHCg4\nCio/gl0vH2LjDoFAz1oH+fmDuPvu3/ZoG0qpga+jFkAyrwLqU3V1dbiui+17744uJsJgdvvzHMfO\nj1VDKMtOcxvs/3mToHw91GzvMBbX7Vo4Ldevq9NRNZRSHTtsEkAkEqGurg4n3EHB3AEvHoVDXNXT\nLEnU7YOckW0vFo9CtMz+HfXPASQmjPxJCQmgjYQVCOIEMzoTdttRNtQSiUS6vb5SKj0cNgmgoKCw\nR+tXV3tEox1Xu203ke/AansOINBGQX1gNXhxyCqGut3gBCA3Yagj5+DH3lZXT0ZGmEgkp8v7cFBO\njz8PpdTh77A5B9AX3nxzKffd95uDE7KGwrC5kFlgX7sNcGAN7F8GeLbWH6+F/Ckw/NSD6+15HcrX\ncNZZH+eSS67s031QSqWXtDgH0BdmzpzNX/+aR2Wl361Ttxe2PAaZRRDIhPr9/j0AvngtZA6xJ4Ab\nNVRCxXoATjllXt8Fr5RSLehloF0QCoW48sprWs+oL4Hanc0Lf7CJYcQ8CGaA50LlJtj2LHgxjj32\nBEaPHtMncSulVFu0C6gb3njjNR544H9paIi2mpednc3UqUeyYsVyf4oD4VyI1zcliEmTjuCmm75J\nTk5P+vmVUurQ9E7gJKiqquK1117h/fdXUFdXR35+PrNnn8SsWScSDmewYcM6Xnjhn7z77jv+5akw\nfPgITj99AfPmnUE43P2rfJRSqrM0AaRQbW0NFRUVhMNhCgoKdfgHpVSf0pPAKZSdnUN2tnb1KKX6\nHz0JrJRSaUoTgFJKpSlNAEoplaY0ASilVJrSBKCUUmlKE4BSSqUpTQBKKZWmBsyNYEoppXqXtgCU\nUipNaQJQSqk0pQlAKaXSlCYApZRKU5oAlFIqTWkCUEqpNKUJQCml0lRKnwdgjJkHPAqsBjwgH9gI\nXC4irZ+32LltPgL8t4gs6eb644H3gXcTJi8WkR90Z3sdvM9YYIaIPOO/vg64AnCBMPAdEVlijHkA\neEREFvbw/a4CSkXkaWPMX4HJwP2AKyL39WC784DrReSShGmPAJ/r7nfYwXsFgDuBo4FMoBr4EjAO\n+L6InJqw7FBgKTAFGAXcBQwFsoHlwI29HV9n+J/Xy8ClIvJIwvT3gXdF5Ko21rkKmCoi3/KPkz8C\n04FPJuG4PAcY294xYYy5HdgNLATWA3NEZLk/73pguIjcbozZDGzF/q4jwKMi8rNOxjCPFsdUF/fh\nW9jf7NvtzP+yiPymE/saxR5DYH+TQez3tqk7cfUGY8wvgbtFZGtvbK8/PBBmcYvC42Hgk8A/UhcS\nq0VkXpLf4wxgKvCMMeYSYAEwX0QajDETgFeNMcf11puJyAMJL88UkeLe2nYb79WtH24nnAOMFJEF\nAMaYC4FfABcCw40xExJ+nFcCfwYc4CngiyLylr/ePcAPgG8lKc5DWQtcAjzix3M0tpDsjFuBP4vI\ne8B7vR1YFysaFcAfjTGzRKS+jflniUidMSYDWGOMeUBE9vZOpO0TkZ8cYpHbgN90Yl9LE8sBY8wX\ngK8BX+5ZhN0nIjf25vb6QwJo4h8oI4AyY8z/AmP810+LyG1+bbgeGO9Pv0pE3jXGfAm4FtiFreVh\njAlja0oTsZn7bhH5mzFmCbASOAqoAv4FnA0MBs46RHx3Aaf4Lx8WkXv8mIr8f58AvgHMTXjPvxtj\nbgA+j63dLwNuwhY+OcaYpcAXgJtFpAFARDYZY44VkRJjTON75wP/68c5EvitiPyu5bZF5CvGmIuA\nbwINwE5sYfOf2JrbMcAgY8xTwBMcrFn+B3AZtsb2iIj8quW+iUhZR59Pwue0GZvc/pu2v6/PADcD\nceA1//1HA78DsvxlbxORJ40xHwLrgCi2Fj/TGPNZYBG2YP+niHjGmPuxhX5jjfhzwLn+97WtsfD3\nfZPUdn+uBIwxZpCIlGNbfn8BxhpjdovIcDjYmm1cyRjz78Bw4BG/Jni9iFxijFkPvA4YYA/wb9j9\n687xfwEHj4k7gJnY73+liFzdYj/WA68CPwK+3sH+5mCPxZouf1IH930B8F9AHVACXAOUA7/1Y9wN\nTADOB27HJteN/mcQw34el2GPi0JjzL3A2wn7ehu2IhECfici/9NGGOOAMj+eto7hIcDD2NapAGeI\nyOQWx/AXsC3vIn+bXxGRD4wxf8S2yrOBe0TkQWPMj4DT/ZgeE5Gf+t/f9f7+PoTtNQlhfy+L/Zbk\nK9jfuQdc4B9jbeoP5wDOMMYsMcasxna7PAF8BLwpImcDs7E73GiLP/3XwHXGmGHAV4E52IO38Wnr\nXwD2icjHgDOB//K/IIC3RWQ+9ouq8WuUq4HT/PlH+jE1/htljDkPe4DNwRYql/k1N7CtmI/58yaI\nyCnYL+47xpjBwNXAl0XkJGANtlb6E2wSeRpboG9M/FBEpKTF5zQZWzCfhf2h3uxPb7ZtY0wIuBT4\nuR/Hs9iDpHG7N2BrNhc0TjPGHAl81t+vucCFpjHz+PvW2cK/DS2/r0Lg+9jWzinAKP/HPRW4y/8u\nrsN27QDkAj8UkUtEZBnw/7A/1FXAO8BJ/nIP+PuAMWY2sFlEdtD2Z1snIt0ujHrJY8BFxhgHe4wv\nPcTyiMj92B9+yxbWROC7/jFQDMyiZ8d/Y4WjzJ83E5hjjBnVRljfBRYYY05pY94LxphXsIXhG9gu\nuy7zP6P7gItE5DRsAXcbtqegSERmA/+OrTAmWoAt5M8EvgcMEpEfYY//GxK2fxzwceBE7HcxxX/P\nQv/3/65fqckCftrBMfwd4Ek/xr9zsILddAxjW3CLROR07HH+O2NMHnAqcBG2lRv317scm7TmAgda\n7NttwIt+t+dngPv9mPOBv/ox7PD3q139IQEs9ptZc7EZchNQCswyxvwF28TPTFh+hf//NuwXMglY\nJSL1fg26sd9vGrZ2gohUYg/wSf68xv79A/50sJk9y/97tYjMS/i3w9/ev0TE89/nTeBIf3nx/z8a\nOMHP0gux/YbjsYX0l/wfwzhsAki0hRYHrzHmbGPMiIRJe7AF80PYLz/sT29r2zdjE+srwMewrYOO\nHOWvu8j/VwQc0WLfuqvl9zUZW0j90/+cjsR+L7uALxhjHsQm/HDCNgTAGHMMICJyKbYm/G3gUWOM\nIyJ7gLXGmJOwtcPGft22PtsiY8z5PdyvnnoYW5Cfiq2Ft6Xdh3m3sF9Etvl/N37OPTn+AWqBof75\nov/BFmKJ3wn+tuuxx+D/0rob6yy/IBrj/7u8k/vT0hCgwv8d4u/XdOw+vuHHsQ/btZbofuw+LsR2\n28Ta2b7BJsW4iERF5Gsi4nGwC2gW9juKikgV7R/D0ziYyFt+p4llxDX+er8HCv3v50bsMfs3DpZ3\nl2Mris9jW2iJEr/fHdjuuKH+vJa/uXb1hwQANNV4r8AeSDcBB0TkcmyzP8fPbmCbNYnWA9ONMdnG\nmCDQ2G++BptU8DPs0djk0tY2OmMNfveP3730Mf+94WABuxZ42T9ozsCe4P4IW2u93v8xHMfBQrnx\n8/8D8F2/9o4xZor/OTTWBMD2Pb4hIldgaxeNn0db274OuN2f5gCfOsS+CbZGfbof+wPYE+GJ+9Zd\nLT/rTdgDc4H/Xr/GJtMfYvu2r8SeJE0s/BpjOBP4gTEm4P9AVwHV/t9gf1Cfw7bEnvOnvQlM8FsF\njbXJ2/GPjVQRkY3YAvMr2KZ8o7AxJtfvDp3exqqJx02jto7nnh7/HwfG+Mn2VmzXRJsJSUTexSa0\nb7YzP4qtwGS0Nb8T9gP5CRWi07BdKh/itwCNMQXYE/6JLsBW2uZjfzON8bXcj7XA8caYgDEmbIx5\n0RjTVOkUkTj2N/UpY8wnaP8YbooHewwmSiwjfuGvdzHwkL9fJ4jIp7DdyD/z3/8z2Nb86cBVxphx\nCdtL/H5HAQXYrjHoQvnWbxIAgIisBn6FrZGeY4x5FdsvvB7blG9rnX3YLLkU+6NvbGbeBxQZY14D\nlmCvEun2CSgReRbYZIx5A/tl/8M/8BM9A1QZY/6FvdLE87P7B8C/jDGLgb3AW/60C4wxl4i9GuRN\n4DV/n/8IXNEi3mc4WNO/EYj5B0lb234beNYYswhbU372EPu2Elvzf80Y8w629r+jo3VaOMsY807j\nPzr4ofvf193AK8aYt7AFzTrsD/ROf/8XYGt9Lf0K22/9nv+9/hXb79/oBX/dJ0TE9d/Pxf6Qbvc/\nu2XYAuC2LuxfsvwNW8iuS5j2S/zjC9t6aelfwD85dOugp8f/28BE//v4B7Ybrc3foO/HbcT7gjHm\nZf/34GDPc3TWWQnH0zLgDuBxY8zr2IrAD4H/A/Ybex7tfuw5hoaEbbyDrTAsxrYqf+1PX+23pAEQ\ne0J9IfY8ymvAX6TFSW0RqcWeZ/y1/z5tHcM/AT5pjHkZWzFLjKXRj4CLE3oJPsR26w339+NF4E7/\n/Uuxx8LL2GM78cqfH2Nb+a8CTwLXiUh7LZx26XDQSqkByRgzFThWRB4xxhRhW4TjWhbefRjPudjz\nLsuMMWcCt4rIGamIpbP61VVASinVBduwJ2VvxF7p9M1UFf6+TcAfjDExP56vpDCWTtEWgFJKpal+\ndQ5AKaVU39EEoJRSaUoTgFJKpSlNAEolMMbM8y/R62iZB4wdoE2pAU0TgFJKpSm9DFQdFowdQvg7\n2BuOJmFvXirHjhvkYAeGm4UdUCyAvbHpCyKyxxhzFnbIkToShhMwxkzG3ohYhL355z9EpPE2+0PF\ns8uP4RTsEAQXix3k7zPYu7qz/X/XisirfqtjBfYmp2zgP7CXEU7H3jn6C2NMLnbws6Owlxn+VET+\n2uUPSymftgDU4eRE7Lg004EvYm/KmYkd1uJ67Jg2F4rIMdi7Pn/j3039J+DTInICdgycRn8CviEi\nx2OHAniEzhuOHfTrOOyYLV829nkG1wPnicgM7J2jtySuJCJHAw9i7zj9N+zt/v/pz74NWO7HeSp2\nsMGJXYhJqWa0BaAOJx82DopmjNmPHd4C7BAF52MH/NrsT7sPO5jc0cBOEVnjT/8T8EO/tj0LO959\n4/Zz/TtOO6txvPkPgVNFxDXGfAo43x9tdR7Nx3tqHL9oC3Y03Bpgi7EjyoJtHeQYY67xX0ewya7Z\naKdKdZYmAHU4afmEr8SxUVq2dh3s8e+1mNe4ThCoE5FjG2cY+8yC0s4GIyJ1/p8e4PhJZRm2hv8q\ntmWS+HCRxPjbGtcliB0j6l0/nmFdiUeplrQLSKWLt7Bj2o/3X1+HHWTrfeywxzP86ZcCiH2Ixnpj\nzBXQ9ECSV3sYwxTsqJA/BhZjBxELdmH9xdiuLfwRJN8HxvYwJpXGNAGodLEHW+g/YYxZhe1+ud5/\ntsOlwIPGmHexT69qdDlwrbFPWboD+GzC0NPdsRL7GMe12DH5q7DPYeis7wPZxj5hajH2/MRHPYhH\npTkdC0gppdKUngNQqhuMMdn4T6Nqw3+KfdSnUv2atgCUUipN6TkApZRKU5oAlFIqTWkCUEqpNKUJ\nQCml0pQmAKWUSlP/HyagLS0GXWp3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a161c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "#cross validation scoring with macro f1 score\n",
    "scorer = make_scorer(f1_score,average='micro')\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  fscores = cross_val_score(model, features, labels, scoring=scorer, cv=CV)\n",
    "  for fold_idx, fscore in enumerate(fscores):\n",
    "    entries.append((model_name, fold_idx, fscore))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'f_score'])\n",
    "\n",
    "sns.boxplot(x='model_name', y='f_score', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='f_score', data=cv_df, \n",
    "              size=10, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "#If you get n_split warning, this means there isn't enough samples for some of the classes in the data.\n",
    "#See distribution plots at the bottom to check which class has few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "LinearSVC                 0.968954\n",
       "LogisticRegression        0.917625\n",
       "MultinomialNB             0.801868\n",
       "RandomForestClassifier    0.578268\n",
       "Name: f_score, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.groupby('model_name').f_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Evaluation\n",
    "Based on above results, let's continue with LinearSVC since it got the best score.\n",
    "\n",
    "We also calibrate the SVC model to get probability output.\n",
    "Source: https://medium.com/@manoveg/multi-class-text-classification-with-probability-prediction-for-each-class-using-linearsvc-in-289189fbb100\n",
    "\n",
    "Note: if the training set is small with respect to the number of features and classes, the reduced training set for each sub-classifier affects performance and the ensembling does not make up for it (or makes it worse). This causes SVC calibration to underperform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAJMCAYAAAAYBLcfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9P8BfLv2BLcbKMgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118cbbbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train and predict\n",
    "model = LinearSVC(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "#y_pred = model.predict(X_test)\n",
    "\n",
    "#calibrate the svc model to get probability output\n",
    "calibrated_svc = CalibratedClassifierCV(base_estimator=model, cv=\"prefit\")\n",
    "calibrated_svc.fit(X_train, y_train)\n",
    "y_pred = calibrated_svc.predict(X_test)\n",
    "prob_pred = []\n",
    "posterior_prob = pd.DataFrame(calibrated_svc.predict_proba(X_test)*100, columns=calibrated_svc.classes_)\n",
    "for index, row in posterior_prob.iterrows():\n",
    "    data = row[y_pred[index]]\n",
    "    prob_pred.append(data)\n",
    "\n",
    "#save quantity model to disk\n",
    "filename = 'pickles/quantity_prediction_model.sav'\n",
    "pickle.dump(model, open(filename,\"wb\"), protocol=2)\n",
    "#save calibrated quantity model to disk\n",
    "filename = 'pickles/calibrated_quantity_model.sav'\n",
    "pickle.dump(calibrated_svc, open(filename,\"wb\"), protocol=2)\n",
    "#save id to quant targets mapping dataframe to disk\n",
    "filename = 'pickles/id_to_quant.pkl'\n",
    "pickle.dump(id_to_quant, open(filename,\"wb\"), protocol=2)\n",
    "#save quantity thresholds to disk\n",
    "filename = 'pickles/quantity_thresholds.pkl'\n",
    "pickle.dump(qty_avg_thresholds, open(filename,\"wb\"), protocol=2)\n",
    "#save vectorizer to disk\n",
    "filename = 'pickles/tfidf.pickle'\n",
    "pickle.dump(tfidf, open(filename, \"wb\"), protocol=2)\n",
    "\n",
    "#plot confusion matrix for Quantity prediction\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=quant_id_df.Quantity.values, yticklabels=quant_id_df.Quantity.values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Removing predictions that fall below confidence threshold\n",
    "num_of_below_threshold = 0\n",
    "#y_pred = y_pred.astype(np.float32)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "new_y_pred = []\n",
    "new_y_test = []\n",
    "for index, pred in enumerate(y_pred):\n",
    "    if prob_pred[index] >= qty_avg_thresholds[pred]:\n",
    "        new_y_pred.append(pred)\n",
    "        new_y_test.append(y_test[index])\n",
    "    else:\n",
    "        num_of_below_threshold += 1\n",
    "\n",
    "display(len(y_pred))\n",
    "#these two numbers should add up to the one above\n",
    "display(len(new_y_pred))\n",
    "display(num_of_below_threshold)\n",
    "#np.isnan(y_pred).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.99      1.00      0.99       704\n",
      "        2.0       1.00      0.98      0.99       305\n",
      "        3.0       1.00      0.98      0.99        88\n",
      "        4.0       0.98      1.00      0.99        88\n",
      "        5.0       1.00      0.50      0.67         2\n",
      "        6.0       1.00      1.00      1.00        19\n",
      "        7.0       0.00      0.00      0.00         2\n",
      "        8.0       0.86      0.86      0.86         7\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1215\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00       698\n",
      "        2.0       1.00      0.99      0.99       299\n",
      "        3.0       1.00      0.99      0.99        87\n",
      "        4.0       1.00      1.00      1.00        86\n",
      "        5.0       1.00      1.00      1.00         1\n",
      "        6.0       1.00      1.00      1.00        15\n",
      "        7.0       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tpham103/anaconda/envs/dog-project/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision, recall, f1 for Quantity prediction before threshold\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=filtered_df['Quantity'].unique().astype('str')))\n",
    "\n",
    "# Calculate precision, recall, f1 for Quantity prediction after thresholds\n",
    "print(metrics.classification_report(new_y_test, new_y_pred, target_names=filtered_df['Quantity'].unique().astype('str')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Features Importance Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights-wrapper\" style=\"border-collapse: collapse; border: none; margin-bottom: 1.5em;\">\n",
       "            <tr>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=1.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=2.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=3.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=4.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=5.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=6.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=8.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                \n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.28%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.231\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        1\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.920\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        one\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.07%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 688 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.80%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 460 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.80%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.335\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        6\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.430\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        one times\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.639\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        4\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.44%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.711\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        3\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.369\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        three\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.377\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        four\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.55%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.922\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        two\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.785\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        2\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.750\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        2\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.01%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.556\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        two\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.01%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 454 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.06%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 683 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.06%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.268\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        4\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.311\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        one daily\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.435\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        two times\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.461\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        3\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.499\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        four\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.640\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        three\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.808\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        one\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.362\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        1\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.433\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        three\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.553\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        3\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.482\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        take three\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.231\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        3 drops\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.203\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        three to\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.31%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 281 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.20%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 616 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.230\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        3 times\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.11%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.255\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        2\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.425\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        one\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.458\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        three times\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.494\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        1\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.460\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        four\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.363\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        4\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.73%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.356\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        take four\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.019\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        4 tablets\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.32%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.953\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        four tablet\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.32%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 243 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.73%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 643 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.73%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.096\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        2\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.251\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        one\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.328\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        4 times\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.479\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        1\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.615\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        four times\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.272\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        5\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.02%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.130\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        five\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.461\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        capsules once\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.427\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        tabs od\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.76%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 90 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.84%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 301 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.413\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        2\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.542\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        times daily\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.30%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.727\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        5 times\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.24%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.740\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        times\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 94.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.801\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        five times\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.92%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.049\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.875\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        6\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.86%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.180\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        six\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.229\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        six to be\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.229\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        six to\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.32%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.199\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        take six\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.883\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        6 tablets\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.859\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        6 tabs\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.568\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        six tablets\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.568\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        take six tablets\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.04%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 185 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 94.46%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 601 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 94.46%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.919\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.380\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        8\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.456\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        taken twice a\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.60%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 117 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.60%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 559 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.457\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        two\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.462\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        four\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.521\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        1\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.535\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        6\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.543\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        five\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.16%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.545\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        one\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.98%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.581\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        2\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 94.24%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.970\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                \n",
       "            </tr>\n",
       "        </table>\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using eli5 to extract features importance for quantity prediction (change labels to quant_id above before running)\n",
    "eli5.show_weights(model, vec=tfidf, top=10, \n",
    "                  target_names=id_to_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part of Text Prediction\n",
    "predict which part of text most associated with frequency and quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.388127e+00</td>\n",
       "      <td>0.412790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>qds</td>\n",
       "      <td>2.874036e-02</td>\n",
       "      <td>0.446551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>drops qds</td>\n",
       "      <td>-5.718501e-19</td>\n",
       "      <td>0.659298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>drops</td>\n",
       "      <td>-5.370660e-02</td>\n",
       "      <td>0.442180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;BIAS&gt;</td>\n",
       "      <td>-8.877488e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target    feature        weight     value\n",
       "0     4.0          4  1.388127e+00  0.412790\n",
       "1     4.0        qds  2.874036e-02  0.446551\n",
       "2     4.0  drops qds -5.718501e-19  0.659298\n",
       "3     4.0      drops -5.370660e-02  0.442180\n",
       "4     4.0     <BIAS> -8.877488e-01  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load prediction model\n",
    "filename = \"pickles/quantity_prediction_model.sav\"\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#load target names mapping\n",
    "filename = \"pickles/id_to_quant.pkl\"\n",
    "loaded_names = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "to_predict = \"4 drops qds\"\n",
    "\n",
    "#make a prediction and show weights contributing to it\n",
    "sample_prediction = eli5.explain_prediction_df(loaded_model, to_predict, vec=tfidf, \n",
    "                     target_names=loaded_names, top_targets=1)\n",
    "\n",
    "display(sample_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=4.0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (score <b>0.475</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.363\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.19%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.888\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.388\">4</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.89%); opacity: 0.81\" title=\"-0.054\">drops</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.35%); opacity: 0.80\" title=\"0.029\">qds</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#highlight the part of text that correspond to prediction\n",
    "highlight_text = eli5.show_prediction(loaded_model, to_predict, vec=tfidf, \n",
    "                     target_names=loaded_names, top_targets=1)\n",
    "\n",
    "display(highlight_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "<style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "<p>\n",
       "<span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.388\">4</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.89%); opacity: 0.81\" title=\"-0.054\">drops</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.35%); opacity: 0.80\" title=\"0.029\">qds</span>\n",
       "</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#parsing the returned html for just the highlighted text\n",
    "try: \n",
    "    from BeautifulSoup import BeautifulSoup\n",
    "except ImportError:\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "parsed_html = BeautifulSoup(highlight_text.data, 'html.parser')\n",
    "parsed_html.find('p').decompose()\n",
    "parsed_html.find('table').decompose()\n",
    "for p in parsed_html.find_all('p'):\n",
    "    if 'style' in p.attrs:\n",
    "        del p.attrs['style']\n",
    "\n",
    "display(parsed_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Getting Probability output\n",
    "source: https://stackoverflow.com/questions/31617530/multiclass-linear-svm-in-python-that-return-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " mapping of classes to quantity values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 1.0,\n",
       " 1.0: 2.0,\n",
       " 2.0: 3.0,\n",
       " 3.0: 4.0,\n",
       " 4.0: 5.0,\n",
       " 5.0: 6.0,\n",
       " 6.0: 7.0,\n",
       " 7.0: 8.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior probabilities for each target class:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031496</td>\n",
       "      <td>1.454106</td>\n",
       "      <td>0.196857</td>\n",
       "      <td>97.906028</td>\n",
       "      <td>0.291742</td>\n",
       "      <td>0.097119</td>\n",
       "      <td>0.022652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2          3         4         5         7\n",
       "0  0.031496  1.454106  0.196857  97.906028  0.291742  0.097119  0.022652"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Posterior probability of the top predicted value:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97.906027744748599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('\\n mapping of classes to quantity values:')\n",
    "display(loaded_names)\n",
    "\n",
    "#transform the input to grams sparse matrix\n",
    "input_grams = tfidf.transform([to_predict])\n",
    "\n",
    "#make prediction and give posterior probabilities of classification\n",
    "predicted_class = calibrated_svc.predict(input_grams)[0]\n",
    "predicted_value = loaded_names[predicted_class]\n",
    "\n",
    "print('Posterior probabilities for each target class:')\n",
    "pred_prob = pd.DataFrame(calibrated_svc.predict_proba(input_grams)*100, columns=calibrated_svc.classes_)\n",
    "display(pred_prob)\n",
    "\n",
    "print('\\n Posterior probability of the top predicted value:')\n",
    "top_prob = pred_prob[predicted_class]\n",
    "display(top_prob[0])\n",
    "print('Predicted value:')\n",
    "display(predicted_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
